{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extract MNIST data</h2>\n",
    "<p style=\"font-size:20px\">You can change the option of one_hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#get mnist data, with one_hot encoding\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "#suppress warnings\n",
    "tf.logging.set_verbosity(old_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define hyperparameters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learning rate\n",
    "lr = 0.01\n",
    "#number of traning steps\n",
    "num_steps =1000\n",
    "#number of batch_size\n",
    "batch_size = 128\n",
    "\n",
    "#network parameters\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "num_input = 784\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define placeholder and Variables</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define neural network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf graph input\n",
    "X = tf.placeholder(tf.float32,[None,num_input],name='X')\n",
    "Y = tf.placeholder(tf.int32,[None,num_classes],name='Y')\n",
    "\n",
    "#Layers weight & bias\n",
    "weights = {\n",
    "    'W1': tf.Variable(tf.random_normal([num_input, n_hidden_1]),name='W1'),\n",
    "    'W2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]),name='W2'),\n",
    "    'Wout': tf.Variable(tf.random_normal([n_hidden_2, num_classes]),name='Wout')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros(shape=[n_hidden_1]),name='b1'),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[n_hidden_2]),name='b2'),\n",
    "    'bout': tf.Variable(tf.zeros(shape=[num_classes]),name='bout')\n",
    "}\n",
    "#define a neural net model\n",
    "def neural_net(x):\n",
    "    layer_1_out = tf.add(tf.matmul(x,weights['W1']),biases['b1'])\n",
    "    layer_2_out = tf.add(tf.matmul(layer_1_out,weights['W2']),biases['b2'])\n",
    "    out = tf.add(tf.matmul(layer_2_out,weights['Wout']),biases['bout'])\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define cost function and accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predicted labels\n",
    "logits = neural_net(X)\n",
    "#define loss\n",
    "loss_generic = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y),name='loss')\n",
    "#define optimizer\n",
    "train_op_generic = tf.train.GradientDescentOptimizer(learning_rate=lr).minimize(loss_generic)\n",
    "#compare the predicted labels with true labels\n",
    "correct_pred = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "\n",
    "#compute the accuracy by taking average\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Execute training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, Accuracy= 0.383\n",
      "Training finished!\n",
      "Testing ACcuracy: 0.8737\n",
      "step 0, Accuracy= 0.250\n",
      "step 1000, Accuracy= 0.906\n",
      "step 2000, Accuracy= 0.922\n",
      "step 3000, Accuracy= 0.906\n",
      "step 4000, Accuracy= 0.945\n",
      "step 5000, Accuracy= 0.977\n",
      "step 6000, Accuracy= 0.953\n",
      "step 7000, Accuracy= 0.977\n",
      "step 8000, Accuracy= 0.953\n",
      "step 9000, Accuracy= 0.969\n",
      "Training finished!\n",
      "Testing ACcuracy: 0.8786\n",
      "step 0, Accuracy= 0.312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bcbb64118888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m#run optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op_generic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sw_k_jung/anaconda3/envs/tensorflowpy34/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sw_k_jung/anaconda3/envs/tensorflowpy34/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sw_k_jung/anaconda3/envs/tensorflowpy34/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sw_k_jung/anaconda3/envs/tensorflowpy34/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sw_k_jung/anaconda3/envs/tensorflowpy34/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sw_k_jung/anaconda3/envs/tensorflowpy34/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#Initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "num_steps_list = [1000,10000]\n",
    "for num_steps in num_steps_list:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(num_steps):\n",
    "            #fetch batch\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            #run optimization\n",
    "            sess.run(train_op_generic, feed_dict={X:batch_x, Y:batch_y})\n",
    "            if i % 1000 ==0:\n",
    "                acc = sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y})\n",
    "                print(\"step \"+str(i)+\", Accuracy= {:.3f}\".format(acc))\n",
    "        print(\"Training finished!\") \n",
    "        print(\"Testing ACcuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "num_steps = 10000\n",
    "for lr in [1, 0.01, 0.001]:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(num_steps):\n",
    "            #fetch batch\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            #run optimization\n",
    "            sess.run(train_op_generic, feed_dict={X:batch_x, Y:batch_y})\n",
    "            if i % 1000 ==0:\n",
    "                acc = sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y})\n",
    "                print(\"step \"+str(i)+\", Accuracy= {:.3f}\".format(acc))\n",
    "        print(\"Training finished!\") \n",
    "        print(\"Testing ACcuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "lr = 0.01\n",
    "for batch_size in [100, 1000]:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(num_steps):\n",
    "            #fetch batch\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            #run optimization\n",
    "            sess.run(train_op_generic, feed_dict={X:batch_x, Y:batch_y})\n",
    "            if i % 1000 ==0:\n",
    "                acc = sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y})\n",
    "                print(\"step \"+str(i)+\", Accuracy= {:.3f}\".format(acc))\n",
    "        print(\"Training finished!\") \n",
    "        print(\"Testing ACcuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Parameter| Value   |  Accuracy |\n",
    "|---|---|---|\n",
    "| Training steps (lr = 0.01, batch_size = 128)  |  1000 | 0.879  |\n",
    "|  Training steps (lr = 0.01, batch_size = 128) | 10000  | 0.878  |\n",
    "|  learining rate  (num_steps = 10000, batch_size = 128)|  1 | 0.877  |\n",
    "|  learning rate (num_steps = 10000, batch_size = 128) |  0.01 | 0.876  |\n",
    "|  Learning rate (num_steps = 10000, batch_size = 128) |  0.001 | 0.865  |\n",
    "|  Batch Size (num_steps = 10000, lr = 0.01)|  100 |  0.864 |\n",
    "|  Batch Size (num_steps = 10000, lr = 0.01)|  1000 | 0.871  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define optimizer\n",
    "train_op_Adam = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss_generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam optimizer\n",
      "step 0, Accuracy= 0.258\n",
      "step 1000, Accuracy= 0.836\n",
      "step 2000, Accuracy= 0.828\n",
      "step 3000, Accuracy= 0.883\n",
      "step 4000, Accuracy= 0.789\n",
      "step 5000, Accuracy= 0.883\n",
      "step 6000, Accuracy= 0.836\n",
      "step 7000, Accuracy= 0.914\n",
      "step 8000, Accuracy= 0.883\n",
      "step 9000, Accuracy= 0.891\n",
      "Training finished!\n",
      "Testing ACcuracy: 0.854\n",
      "adagrad optimizer\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10000\n",
    "batch_size = 128\n",
    "print('adam optimizer')\n",
    "with tf.Session() as sess:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        for i in range(num_steps):\n",
    "            #fetch batch\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            #run optimization\n",
    "            sess.run(train_op_Adam, feed_dict={X:batch_x, Y:batch_y})\n",
    "            if i % 1000 ==0:\n",
    "                acc = sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y})\n",
    "                print(\"step \"+str(i)+\", Accuracy= {:.3f}\".format(acc))\n",
    "        print(\"Training finished!\") \n",
    "        print(\"Testing ACcuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "print('adagrad optimizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Your results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_hidden_1 = 1024\n",
    "n_hidden_2 = 1024\n",
    "n_hidden_3 = 10\n",
    "num_input = 784\n",
    "#tf graph input\n",
    "X = tf.placeholder(tf.float32,[None,num_input],name='X')\n",
    "Y = tf.placeholder(tf.int32,[None,num_classes],name='Y')\n",
    "\n",
    "#Layers weight & bias\n",
    "weights = {\n",
    "    'W1': tf.Variable(tf.random_normal([num_input, n_hidden_1]),name='W1'),\n",
    "    'W2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]),name='W2'),\n",
    "    'W3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]),name='W3'),\n",
    "    'Wout': tf.Variable(tf.random_normal([n_hidden_2, num_classes]),name='Wout')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.zeros(shape=[n_hidden_1]),name='b1'),\n",
    "    'b2': tf.Variable(tf.zeros(shape=[n_hidden_2]),name='b2'),\n",
    "    'b3': tf.Variable(tf.zeros(shape=[n_hidden_3]),name='b3'),\n",
    "    'bout': tf.Variable(tf.zeros(shape=[num_classes]),name='bout')\n",
    "}\n",
    "\n",
    "def neural_net_extended(x):\n",
    "    layer_1_out = tf.nn.relu(tf.add(tf.matmul(x,weights['W1']),biases['b1']))\n",
    "    layer_2_out = tf.nn.relu(tf.add(tf.matmul(layer_1_out,weights['W2']),biases['b2']))\n",
    "    layer_3_out = tf.nn.relu(tf.add(tf.matmul(layer_2_out,weights['W3']),biases['b3']))\n",
    "    out = (tf.add(tf.matmul(layer_2_out,weights['Wout']),biases['bout']))\n",
    "    return out\n",
    "\n",
    "#predicted labels\n",
    "logits_extended = neural_net_extended(X)\n",
    "#define loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits_extended,labels=Y),name='loss')\n",
    "#define optimizer\n",
    "train_extended = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "#compare the predicted labels with true labels\n",
    "correct_pred = tf.equal(tf.argmax(logits_extended,1),tf.argmax(Y,1))\n",
    "\n",
    "#compute the accuracy by taking average\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, Accuracy= 0.312\n",
      "step 1000, Accuracy= 1.000\n",
      "step 2000, Accuracy= 1.000\n",
      "step 3000, Accuracy= 1.000\n",
      "step 4000, Accuracy= 1.000\n",
      "step 5000, Accuracy= 1.000\n",
      "step 6000, Accuracy= 1.000\n",
      "step 7000, Accuracy= 1.000\n",
      "step 8000, Accuracy= 1.000\n",
      "step 9000, Accuracy= 1.000\n",
      "step 10000, Accuracy= 1.000\n",
      "step 11000, Accuracy= 1.000\n",
      "step 12000, Accuracy= 1.000\n",
      "step 13000, Accuracy= 1.000\n",
      "step 14000, Accuracy= 1.000\n",
      "step 15000, Accuracy= 1.000\n",
      "step 16000, Accuracy= 1.000\n",
      "step 17000, Accuracy= 1.000\n",
      "step 18000, Accuracy= 1.000\n",
      "step 19000, Accuracy= 1.000\n",
      "step 20000, Accuracy= 1.000\n",
      "step 21000, Accuracy= 1.000\n",
      "step 22000, Accuracy= 1.000\n",
      "step 23000, Accuracy= 1.000\n",
      "step 24000, Accuracy= 1.000\n",
      "step 25000, Accuracy= 1.000\n",
      "step 26000, Accuracy= 1.000\n",
      "step 27000, Accuracy= 1.000\n",
      "step 28000, Accuracy= 1.000\n",
      "step 29000, Accuracy= 1.000\n",
      "Training finished!\n",
      "Testing ACcuracy: 0.9542\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "batch_size = 128\n",
    "num_steps = 30000\n",
    "lr = 0.01\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_steps):\n",
    "        #fetch batch\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        #run optimization\n",
    "        sess.run(train_extended, feed_dict={X:batch_x, Y:batch_y})\n",
    "        if i % 1000 ==0:\n",
    "            acc = sess.run(accuracy,feed_dict={X:batch_x, Y:batch_y})\n",
    "            print(\"step \"+str(i)+\", Accuracy= {:.3f}\".format(acc))\n",
    "    print(\"Training finished!\") \n",
    "    print(\"Testing ACcuracy:\", sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the optimizer/batch_size/num_steps/learning rate did not drastically changed. The parameter that contributed the most to the highest accuracy (95.4%) was the activation function (ReLU) applied to both first and second hidden layer. \n",
    "Number of neurons were also increased (# of nodes in first hidden layer 1024, # of nodes in the second hidden layer 1024). Interestingly, addition of a layer or changing the activation function to sigmoid did not increase the accuracy result at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
