{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import timeit\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load training, validation, testing set from your preprocessed files</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_path = 'dogs-vs-cats-preprocessed/'\n",
    "\n",
    "train_files_path = os.path.join(files_path, 'train*')\n",
    "train_files = sorted(glob(train_files_path))\n",
    "valid_files_path = os.path.join(files_path, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 227\n",
    "X_train = np.empty((0, img_size, img_size, 3))\n",
    "Y_train = np.empty((0,2));\n",
    "for f in train_files:\n",
    "    train_image, train_labels = pickle.load(open(f, 'rb'))\n",
    "    X_train = np.concatenate((X_train, train_image), axis = 0)\n",
    "    Y_train = np.concatenate((Y_train, train_labels), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24500, 227, 227, 3) (24500, 2) (500, 227, 227, 3) (500, 2)\n"
     ]
    }
   ],
   "source": [
    "X_valid, Y_valid = pickle.load(open(valid_files_path, 'rb'))\n",
    "print(X_train.shape, Y_train.shape, X_valid.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "lr = 0.01\n",
    "num_conv_layers = 6\n",
    "N = X_train.shape[0]\n",
    "def mini_batch(features,labels,batch_size):\n",
    "    for start_idx in range(0, N - batch_size + 1, batch_size):\n",
    "        indices = np.arange(features.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        excerpt = indices[start_idx:start_idx + batch_size]\n",
    "        yield features[excerpt], labels[excerpt]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AlexNet</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initalize_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(\n",
    "        shape = shape, \n",
    "        mean = 0, \n",
    "        stddev = 0.1))\n",
    "def initialize_bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1,shape=shape))\n",
    "class AlexNet:\n",
    "    def __init__(self,learning_rate = lr, batch_size = batch_size,num_epochs = num_epochs):\n",
    "        self.learning_rate = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = num_epochs\n",
    "    \n",
    "    def model(self,x):\n",
    "        with tf.name_scope(\"conv1\") as scope:\n",
    "            conv1_W = initalize_weights((11,11,3,96))\n",
    "            conv1_b = initialize_bias([96])\n",
    "            conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 4, 4, 1], padding='SAME') + conv1_b\n",
    "            conv1 = tf.nn.relu(conv1)\n",
    "\n",
    "            mean, var = tf.nn.moments(conv1, [0, 1, 2])\n",
    "            conv1_bn = tf.nn.batch_normalization(conv1, mean, var, 0, 1, 0)\n",
    "            \n",
    "            conv1_maxpool = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name = scope)\n",
    "        \n",
    "        with tf.name_scope(\"conv2\") as scope:\n",
    "            conv2_W = initalize_weights((5,5,96,256))\n",
    "            conv2_b = initialize_bias([256])\n",
    "            conv2   = tf.nn.conv2d(conv1_maxpool, conv2_W, strides=[1, 1, 1, 1], padding='SAME') + conv2_b\n",
    "            conv2 = tf.nn.relu(conv2)\n",
    "\n",
    "            mean, var = tf.nn.moments(conv2, [0, 1, 2])\n",
    "            conv2_bn = tf.nn.batch_normalization(conv2, mean, var, 0, 1, 0)\n",
    "            \n",
    "            conv2_maxpool = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name = scope)\n",
    "        \n",
    "        with tf.name_scope(\"conv3\") as scope:\n",
    "            conv3_W = initalize_weights((3,3,256,512))\n",
    "            conv3_b = initialize_bias([512])\n",
    "            conv3   = tf.nn.conv2d(conv2_maxpool, conv3_W, strides=[1, 1, 1, 1], padding='SAME') + conv3_b\n",
    "            conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "            mean, var = tf.nn.moments(conv3, [0, 1, 2])\n",
    "            conv3_bn = tf.nn.batch_normalization(conv3, mean, var, 0, 1, 0)\n",
    "            \n",
    "            conv3 = tf.nn.max_pool(conv3, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name = scope)\n",
    "            \n",
    "        with tf.name_scope(\"conv4\") as scope:\n",
    "            conv4_W = initalize_weights((3,3,512,1024))\n",
    "            conv4_b = initialize_bias([1024])\n",
    "            conv4   = tf.nn.conv2d(conv3, conv4_W, strides=[1, 1, 1, 1], padding='SAME') + conv4_b\n",
    "            conv4 = tf.nn.relu(conv4)\n",
    "\n",
    "            mean, var = tf.nn.moments(conv4, [0, 1, 2])\n",
    "            conv4_bn = tf.nn.batch_normalization(conv4, mean, var, 0, 1, 0)\n",
    "            \n",
    "            conv4 = tf.nn.max_pool(conv4, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name = scope)\n",
    "            \n",
    "        with tf.name_scope(\"conv5\") as scope:\n",
    "            conv5_W = initalize_weights((3,3,1024,512))\n",
    "            conv5_b = initialize_bias([512])\n",
    "            conv5   = tf.nn.conv2d(conv4, conv5_W, strides=[1, 1, 1, 1], padding='SAME') + conv5_b\n",
    "            conv5 = tf.nn.relu(conv5)\n",
    "\n",
    "            mean, var = tf.nn.moments(conv5, [0, 1, 2])\n",
    "            conv5_bn = tf.nn.batch_normalization(conv5, mean, var, 0, 1, 0)\n",
    "            \n",
    "            conv5 = tf.nn.max_pool(conv4, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME', name = scope)\n",
    "        \n",
    "        with tf.name_scope('FC1') as scope:\n",
    "            pool5_flat = tf.contrib.layers.flatten(conv5)\n",
    "            fc1 = tf.layers.dense(pool5_flat, units=1024, activation=tf.nn.relu, name=scope)\n",
    "            # fc6_dropout = tf.layers.dropout(fc6, 0.5)\n",
    "\n",
    "        with tf.name_scope('FC2') as scope:\n",
    "            fc2 = tf.layers.dense(fc1, units=256, activation=tf.nn.relu, name=scope)\n",
    "            # fc7_dropout = tf.layers.dropout(fc7, 0.5)\n",
    "\n",
    "        with tf.name_scope('logits') as scope:\n",
    "            logits = tf.layers.dense(fc2, units=2, activation=tf.nn.softmax, name=scope)    \n",
    "        return logits\n",
    "    \n",
    "    def train(self):\n",
    "        X = tf.placeholder(tf.float32, shape=[None, 227,227,3])\n",
    "        Y = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "        logits = self.model(X)\n",
    "        loss = tf.nn.l2_loss(tf.square(logits - Y))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(loss)\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            for i in range(num_epochs):\n",
    "                #fetch batch\n",
    "                for img_batch, labels_batch in mini_batch(X_train,Y_train, self.batch_size):\n",
    "                    sess.run(optimizer, feed_dict={X:img_batch, Y:labels_batch})\n",
    "                acc = sess.run(accuracy,feed_dict={X:X_train, Y:Y_train})\n",
    "                print(\"step \"+str(i)+\", Accuracy= {:.3f}\".format(acc))\n",
    "            print(\"Training finished!\") \n",
    "            print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={X:X_valid, Y:Y_valid})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alex_net = AlexNet()\n",
    "alex_net.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and Optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training and validation</h1>\n",
    "<h2>Train your model only 10 epochs</h2>\n",
    "<p style=\"font-size:20px\">1. Print out training accuracy and validation accuracy each training epoch</p>\n",
    "<p style=\"font-size:20px\">2. Print out training time each training epoch</p>\n",
    "<p style=\"font-size:20px\">3. Your goal is to reach 85% validation accuracy in 10 training epochs. If you reach that, you can perform testing, print out your test accuracy. Plot out the ten images with title that contains the probability of the labeled class.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
