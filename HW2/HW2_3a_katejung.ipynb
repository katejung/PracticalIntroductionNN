{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extract MNIST data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#get mnist data, with one_hot encoding, reshape = False (that means images are not flatten)\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",reshape=False,one_hot=True)\n",
    "#suppress warnings\n",
    "tf.logging.set_verbosity(old_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prepare training, validation and testing data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "x_validation, y_validation = mnist.validation.images, mnist.validation.labels\n",
    "x_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "#pad images with 0s (28x28 to 32x32)\n",
    "x_train      = np.pad(x_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "x_validation = np.pad(x_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "x_test       = np.pad(x_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "print(x_train.shape)\n",
    "def padImage(X):\n",
    "    return np.pad(X, ((0,0),(2,2),(2,2),(0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#learning rate\n",
    "lr = 0.01\n",
    "#number of traning steps\n",
    "num_epochs =1000\n",
    "#number of batch_size\n",
    "batch_size = 128\n",
    "\n",
    "#network parameters\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 100\n",
    "num_input = 784\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,32, 32, 1],name='X')\n",
    "Y = tf.placeholder(tf.int32,[None,num_classes],name='Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define LeNet-5</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeNet5(X):\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=[5, 5, 1, 6], mean=0, stddev=0.08))\n",
    "    conv1_b = tf.Variable(tf.zeros(shape=6))\n",
    "\n",
    "    conv1 = tf.nn.conv2d(X, conv1_W, strides=[1,1,1,1], padding='VALID')+ conv1_b\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    conv1_bn = tf.layers.batch_normalization(conv1_pool)\n",
    "    \n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=[5, 5, 6, 16], mean=0, stddev=0.08))\n",
    "    conv2_b = tf.Variable(tf.zeros(shape=16))\n",
    "\n",
    "    conv2 = tf.nn.conv2d(conv1_bn, conv2_W, strides=[1,1,1,1], padding='VALID')+ conv2_b\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "    conv2_bn = tf.layers.batch_normalization(conv2_pool)\n",
    "    \n",
    "    fc0   = tf.contrib.layers.flatten(conv2_bn)\n",
    "    fc1_w = tf.Variable(tf.truncated_normal(shape=[400,120], mean=0, stddev=0.08))\n",
    "    fc1_b = tf.Variable(tf.zeros(shape=120))\n",
    "    fc1   = tf.matmul(fc0, fc1_w) + fc1_b\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc2_w = tf.Variable(tf.truncated_normal(shape=[120,84], mean=0, stddev=0.08))\n",
    "    fc2_b = tf.Variable(tf.zeros(shape=84))\n",
    "    fc2   = tf.matmul(fc1, fc2_w) + fc2_b\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "    \n",
    "    fc3_w = tf.Variable(tf.truncated_normal(shape=[84,10], mean=0, stddev=0.08))\n",
    "    fc3_b = tf.Variable(tf.zeros(shape=10))\n",
    "    logits   = tf.matmul(fc2, fc3_w) + fc3_b\n",
    "    return logits\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = LeNet5(X)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "training_operation = optimizer.minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training, validating, testing</h1>\n",
    "<h2>1. Print out validation accuracy after each training epoch</h2>\n",
    "<h2>2. Print out training time on each epoch</h2>\n",
    "<h2>3. Print out testing accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, Train time = 0.238\n",
      "     Train Accuracy= 0.100\n",
      "     Validation Accuracy= 0.096\n",
      "step 100, Train time = 0.053\n",
      "     Train Accuracy= 0.954\n",
      "     Validation Accuracy= 0.960\n",
      "step 200, Train time = 0.072\n",
      "     Train Accuracy= 0.972\n",
      "     Validation Accuracy= 0.973\n",
      "step 300, Train time = 0.050\n",
      "     Train Accuracy= 0.972\n",
      "     Validation Accuracy= 0.972\n",
      "step 400, Train time = 0.053\n",
      "     Train Accuracy= 0.980\n",
      "     Validation Accuracy= 0.980\n",
      "step 500, Train time = 0.057\n",
      "     Train Accuracy= 0.981\n",
      "     Validation Accuracy= 0.982\n",
      "step 600, Train time = 0.055\n",
      "     Train Accuracy= 0.982\n",
      "     Validation Accuracy= 0.980\n",
      "step 700, Train time = 0.073\n",
      "     Train Accuracy= 0.983\n",
      "     Validation Accuracy= 0.979\n",
      "step 800, Train time = 0.073\n",
      "     Train Accuracy= 0.987\n",
      "     Validation Accuracy= 0.985\n",
      "step 900, Train time = 0.071\n",
      "     Train Accuracy= 0.986\n",
      "     Validation Accuracy= 0.983\n",
      "Training finished!\n",
      "Testing ACcuracy: 0.9842\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "  \n",
    "    for i in range(num_epochs):\n",
    "        #fetch batch\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = padImage(batch_x)\n",
    "        #run optimization\n",
    "        start = time.time()\n",
    "        sess.run(training_operation, feed_dict={X:batch_x, Y:batch_y})\n",
    "        end = time.time()\n",
    "        if i % 100 ==0:\n",
    "            print(\"step \"+str(i)+\", Train time = {:.3f}\".format(end-start))\n",
    "            acc = sess.run(accuracy,feed_dict={X:x_train, Y:y_train})\n",
    "            print(\"     Train Accuracy= {:.3f}\".format(acc))\n",
    "            acc = sess.run(accuracy,feed_dict={X:x_validation, Y:y_validation})\n",
    "            print(\"     Validation Accuracy= {:.3f}\".format(acc))\n",
    "            \n",
    "    end = time.time()\n",
    "    print(\"Training finished!\") \n",
    "    print(\"Testing ACcuracy:\", sess.run(accuracy, feed_dict={X:x_test, Y:y_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
