{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from load_cifar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Hyper-perparmeter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate\n",
    "lr = 0.01\n",
    "#number of traning steps\n",
    "num_epochs =20\n",
    "\n",
    "#number of batch_size\n",
    "batch_size = 128\n",
    "\n",
    "#network parameters\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 32, 32, 3], name='X')\n",
    "Y = tf.placeholder(tf.float32, shape=[None, num_classes], name='Y')\n",
    "drop_prob = tf.placeholder(tf.float32, name='drop_prob')\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define Neural Network Architecture</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def initalize_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(\n",
    "        shape = shape, \n",
    "        mean = 0, \n",
    "        stddev = 0.01))\n",
    "def initialize_bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1,shape=shape))\n",
    "\n",
    "def fully_connected_net(x, drop_prob):\n",
    "    x = tf.reshape(x,[-1, 3072])    \n",
    "    \n",
    "    W_fc1 = initalize_weights([3072, 4000])\n",
    "    b_fc1 = initialize_bias([4000])\n",
    "    h_fc1 = tf.nn.relu(tf.add(tf.matmul(x, W_fc1), b_fc1))\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, rate = drop_prob)\n",
    "    mean, var = tf.nn.moments(h_fc1_drop, [0, 1])\n",
    "    h_bn1 = tf.nn.batch_normalization(h_fc1_drop, mean ,var, 0, 1, 0)\n",
    "    \n",
    "    W_fc2 = initalize_weights([4000, 1200])\n",
    "    b_fc2 = initialize_bias([1200])\n",
    "    h_fc2 = tf.nn.relu(tf.add(tf.matmul(h_bn1, W_fc2), b_fc2))\n",
    "    h_fc2_drop = tf.nn.dropout(h_fc2, rate = drop_prob)\n",
    "    mean, var = tf.nn.moments(h_fc2_drop, [0, 1])\n",
    "    h_bn2 = tf.nn.batch_normalization(h_fc2_drop, mean ,var, 0, 1, 0)\n",
    "\n",
    "    W_fc3 = initalize_weights([1200, 10])\n",
    "    b_fc3 = initialize_bias([10])\n",
    "    h_fc3 = tf.nn.relu(tf.add(tf.matmul(h_bn2, W_fc3), b_fc3))\n",
    "    h_fc3_drop = tf.nn.dropout(h_fc3, rate = drop_prob)\n",
    "    mean, var = tf.nn.moments(h_fc3_drop, [0, 1])\n",
    "    logits = tf.nn.batch_normalization(h_fc3_drop, mean ,var, 0, 1, 0)\n",
    "\n",
    "#     W_fc4 = initalize_weights([100, 10])\n",
    "#     b_fc4 = initialize_bias([10])\n",
    "#     logits = tf.nn.softmax(tf.add(tf.matmul(h_bn3, W_fc4), b_fc4))\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Define cost andoptimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted labels\n",
    "logits = fully_connected_net(X,drop_prob)\n",
    "#define loss\n",
    "\n",
    "# Loss and Optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "train_optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.01).minimize(loss)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32),name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training and testing</h1>\n",
    "<h2>1.Print out validation accuracy after each training poch</h2>\n",
    "<h2>2.Print out training time you spend on each epoch</h2>\n",
    "<h2>3.Print out testing accuracy in the end</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, Y_valid = pickle.load(open('cifar-preprocessed/batch_valid','rb'))\n",
    "test_features, test_labels = pickle.load(open('cifar-preprocessed/batch_test','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, Train Time = 6.285\n",
      "    Validation Accuracy= 0.368\n",
      "step 1, Train Time = 6.070\n",
      "    Validation Accuracy= 0.386\n",
      "step 2, Train Time = 5.971\n",
      "    Validation Accuracy= 0.425\n",
      "step 3, Train Time = 5.965\n",
      "    Validation Accuracy= 0.443\n",
      "step 4, Train Time = 5.967\n",
      "    Validation Accuracy= 0.425\n",
      "step 5, Train Time = 6.011\n",
      "    Validation Accuracy= 0.447\n",
      "step 6, Train Time = 6.056\n",
      "    Validation Accuracy= 0.453\n",
      "step 7, Train Time = 5.965\n",
      "    Validation Accuracy= 0.464\n",
      "step 8, Train Time = 5.963\n",
      "    Validation Accuracy= 0.451\n",
      "step 9, Train Time = 5.968\n",
      "    Validation Accuracy= 0.450\n",
      "step 10, Train Time = 5.976\n",
      "    Validation Accuracy= 0.465\n",
      "step 11, Train Time = 6.041\n",
      "    Validation Accuracy= 0.493\n",
      "step 12, Train Time = 5.975\n",
      "    Validation Accuracy= 0.473\n",
      "step 13, Train Time = 5.956\n",
      "    Validation Accuracy= 0.469\n",
      "step 14, Train Time = 5.964\n",
      "    Validation Accuracy= 0.498\n",
      "step 15, Train Time = 5.974\n",
      "    Validation Accuracy= 0.496\n",
      "step 16, Train Time = 5.958\n",
      "    Validation Accuracy= 0.478\n",
      "step 17, Train Time = 5.964\n",
      "    Validation Accuracy= 0.494\n",
      "step 18, Train Time = 5.987\n",
      "    Validation Accuracy= 0.499\n",
      "step 19, Train Time = 5.952\n",
      "    Validation Accuracy= 0.490\n",
      "Training finished!\n",
      "Testing ACcuracy: 0.5047\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Initialize the variables\n",
    "    sess.run(init)\n",
    "    #fetch batch\n",
    "    for i in range(num_epochs):\n",
    "        start = time.time()\n",
    "        for batch_id in np.arange(1,6):\n",
    "            for fearues_batch, labels_batch in load_preprocessed_training_batch(batch_id,batch_size):\n",
    "                #run optimization\n",
    "                sess.run(train_optimizer, feed_dict={X:fearues_batch, \n",
    "                                                     Y:labels_batch,\n",
    "                                                     learning_rate : lr,\n",
    "                                                         drop_prob: 0.3})\n",
    "        end= time.time()\n",
    "        print(\"step \"+str(i)+\", Train Time = {:.3f}\".format(end-start))\n",
    "#         acc = sess.run(accuracy,feed_dict={X:fearues_batch,\n",
    "#                                            Y:labels_batch,\n",
    "#                                            learning_rate : lr,\n",
    "#                                           drop_prob : .0})\n",
    "#         print(\"    Train Accuracy= {:.3f}\".format(acc))\n",
    "        acc = sess.run(accuracy,feed_dict={X:X_valid,\n",
    "                                           Y:Y_valid,\n",
    "                                           learning_rate : lr,\n",
    "                                          drop_prob : 0.0})\n",
    "        print(\"    Validation Accuracy= {:.3f}\".format(acc))\n",
    "    print(\"Training finished!\") \n",
    "    print(\"Testing ACcuracy:\", sess.run(accuracy, \n",
    "                                        feed_dict={X:test_features, \n",
    "                                                   Y:test_labels,\n",
    "                                                   learning_rate : lr,\n",
    "                                                  drop_prob:0.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "Under the Same Condition:\n",
    "\n",
    "Best Accuracy W/O batch normalization: **0.40**\n",
    "\n",
    "Best Accuracy with batch size 256: **0.45**\n",
    "\n",
    "Best Accuracy with dropout prob 0.5: **0.4255**\n",
    "\n",
    "Best Accuracy with Adam Optimizer: **0.41**\n",
    "\n",
    "Best Accuracy with 10 epochs: **0.47**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
